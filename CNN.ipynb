{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1s-nSJAaa8H-vR1N_bsEm2AiK_jKzRWL_",
      "authorship_tag": "ABX9TyPr31zZtCyhnZ0lxmuF1hEC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pradeep23-01/General-CNN-models/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEIoFFZqJjI5"
      },
      "source": [
        "# Importing the Libreries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0-CgV5jJnLH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "304325f1-e6bc-466e-d4cd-8097eb409c3c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiibt9MEtowO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT6hESSnuTNm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "67c0e85d-e0aa-4aa8-eb7f-76a6f27d65de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXNcQgmEIyI3"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWYhFusaIyNo"
      },
      "source": [
        "# Preprocessing the the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaaR06IdJJV0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88395a92-39c7-4cc5-ff01-f19de3aebbf4"
      },
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "training_set=train_datagen.flow_from_directory('/content/drive/My Drive/Training_set/Training_set',\n",
        "        target_size=(64,64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1486 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMkFMo8cIykM"
      },
      "source": [
        "# Preprocessing the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsj9K1Z_ObMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f698ed6-a404-4d22-bf90-028bec7791f8"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/test',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 382 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2BeyAWRIyvo"
      },
      "source": [
        "# Building a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA59LwvxSlrH"
      },
      "source": [
        "# Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9p0YcWsSvDV"
      },
      "source": [
        "cnn=tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHX-EoXuSezh"
      },
      "source": [
        "# Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTW4Ax2kSeJw"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size= 3,activation='relu',input_shape=[64,64,3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLiOG23LULsF"
      },
      "source": [
        "# Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHu-rLHVUOeI"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BahK9fmvUqWf"
      },
      "source": [
        "# Second Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYIFW1ZAUt99"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fWSjax5U64M"
      },
      "source": [
        "# Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAzHHUJTVAkk"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eEhBYGBU7uk"
      },
      "source": [
        "# Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8LhXmVIVtwd"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LicCBAfpV9MM"
      },
      "source": [
        "# Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MbJvzmDWAg_"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC6cRyChXUsK"
      },
      "source": [
        "# Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivM8y92LYPRO"
      },
      "source": [
        "# Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytaBCcP3X3xM"
      },
      "source": [
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZBPneWsXXZd"
      },
      "source": [
        "# Training the CNN on tarining set and evaluating on test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6POG6OpzY07y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "18ce6bea-c738-4810-a254-0a7197789264"
      },
      "source": [
        "cnn.fit(x=training_set,validation_data=test_set,epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "47/47 [==============================] - 434s 9s/step - loss: 0.5302 - accuracy: 0.7416 - val_loss: 1.0731 - val_accuracy: 0.5524\n",
            "Epoch 2/25\n",
            "47/47 [==============================] - 13s 281ms/step - loss: 0.4186 - accuracy: 0.8163 - val_loss: 1.6734 - val_accuracy: 0.4372\n",
            "Epoch 3/25\n",
            "47/47 [==============================] - 13s 281ms/step - loss: 0.3479 - accuracy: 0.8479 - val_loss: 1.6955 - val_accuracy: 0.4398\n",
            "Epoch 4/25\n",
            "47/47 [==============================] - 14s 289ms/step - loss: 0.3414 - accuracy: 0.8526 - val_loss: 1.8083 - val_accuracy: 0.4529\n",
            "Epoch 5/25\n",
            "47/47 [==============================] - 13s 286ms/step - loss: 0.3023 - accuracy: 0.8721 - val_loss: 2.1837 - val_accuracy: 0.4503\n",
            "Epoch 6/25\n",
            "47/47 [==============================] - 13s 284ms/step - loss: 0.2612 - accuracy: 0.8984 - val_loss: 1.8647 - val_accuracy: 0.5288\n",
            "Epoch 7/25\n",
            "47/47 [==============================] - 13s 282ms/step - loss: 0.2563 - accuracy: 0.8957 - val_loss: 2.2252 - val_accuracy: 0.4843\n",
            "Epoch 8/25\n",
            "47/47 [==============================] - 13s 286ms/step - loss: 0.2775 - accuracy: 0.8903 - val_loss: 1.8176 - val_accuracy: 0.4738\n",
            "Epoch 9/25\n",
            "47/47 [==============================] - 14s 289ms/step - loss: 0.2163 - accuracy: 0.9166 - val_loss: 1.5091 - val_accuracy: 0.5759\n",
            "Epoch 10/25\n",
            "47/47 [==============================] - 13s 282ms/step - loss: 0.2132 - accuracy: 0.9139 - val_loss: 2.8228 - val_accuracy: 0.4188\n",
            "Epoch 11/25\n",
            "47/47 [==============================] - 13s 280ms/step - loss: 0.2206 - accuracy: 0.9145 - val_loss: 2.3484 - val_accuracy: 0.4948\n",
            "Epoch 12/25\n",
            "47/47 [==============================] - 13s 280ms/step - loss: 0.1700 - accuracy: 0.9381 - val_loss: 2.0414 - val_accuracy: 0.5602\n",
            "Epoch 13/25\n",
            "47/47 [==============================] - 13s 284ms/step - loss: 0.1751 - accuracy: 0.9320 - val_loss: 2.9825 - val_accuracy: 0.4372\n",
            "Epoch 14/25\n",
            "47/47 [==============================] - 13s 283ms/step - loss: 0.1610 - accuracy: 0.9421 - val_loss: 5.1377 - val_accuracy: 0.3429\n",
            "Epoch 15/25\n",
            "47/47 [==============================] - 13s 282ms/step - loss: 0.2069 - accuracy: 0.9145 - val_loss: 3.3192 - val_accuracy: 0.4503\n",
            "Epoch 16/25\n",
            "47/47 [==============================] - 13s 283ms/step - loss: 0.1521 - accuracy: 0.9408 - val_loss: 1.7088 - val_accuracy: 0.5942\n",
            "Epoch 17/25\n",
            "47/47 [==============================] - 13s 287ms/step - loss: 0.1595 - accuracy: 0.9388 - val_loss: 3.6503 - val_accuracy: 0.4215\n",
            "Epoch 18/25\n",
            "47/47 [==============================] - 13s 285ms/step - loss: 0.1255 - accuracy: 0.9529 - val_loss: 3.3854 - val_accuracy: 0.4895\n",
            "Epoch 19/25\n",
            "47/47 [==============================] - 13s 284ms/step - loss: 0.1197 - accuracy: 0.9536 - val_loss: 3.2890 - val_accuracy: 0.5079\n",
            "Epoch 20/25\n",
            "47/47 [==============================] - 13s 283ms/step - loss: 0.1232 - accuracy: 0.9576 - val_loss: 3.9354 - val_accuracy: 0.4817\n",
            "Epoch 21/25\n",
            "47/47 [==============================] - 13s 283ms/step - loss: 0.1365 - accuracy: 0.9509 - val_loss: 2.7861 - val_accuracy: 0.5419\n",
            "Epoch 22/25\n",
            "47/47 [==============================] - 13s 283ms/step - loss: 0.1049 - accuracy: 0.9630 - val_loss: 3.6127 - val_accuracy: 0.5000\n",
            "Epoch 23/25\n",
            "47/47 [==============================] - 13s 282ms/step - loss: 0.0997 - accuracy: 0.9623 - val_loss: 3.9800 - val_accuracy: 0.5052\n",
            "Epoch 24/25\n",
            "47/47 [==============================] - 13s 283ms/step - loss: 0.0768 - accuracy: 0.9717 - val_loss: 4.0745 - val_accuracy: 0.5157\n",
            "Epoch 25/25\n",
            "47/47 [==============================] - 13s 281ms/step - loss: 0.0877 - accuracy: 0.9670 - val_loss: 4.4368 - val_accuracy: 0.4817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff3aed352e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70FBCZ63YKvJ"
      },
      "source": [
        "# Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trW425j9cqtd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e38e5a15-4302-4d5f-edef-1098b55e58d7"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_image=image.load_img( '/content/drive/My Drive/test/test/electric car/image-801.jpeg',\n",
        "        target_size=(64, 64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=cnn.predict(test_image)\n",
        "training_set.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'electric bus': 0, 'electric car': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}